---
title: 'Minería de Flujo de Datos: Trabajo Final'
author: "Juanjo Sierra"
date: "25 de abril de 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Ejercicio 1: Entrenamiento offline (estacionario) y evaluación posterior.

### Entrenar un clasificador HoeffdingTree offline (estacionario, aprender modelo únicamente), sobre un total de 1.000.000 de instancias procedentes de un flujo obtenido por el generador WaveFormGenerator con semilla aleatoria igual a 2. Evaluar posteriormente (sólo evaluación) con 1.000.000 de instancias generadas por el mismo tipo de generador, con semilla aleatoria igual a 4. Repita el proceso varias veces con la misma semilla en evaluación y diferentes semillas en entrenamiento, para crear una población de resultados. Anotar como resultados los valores de porcentajes de aciertos en la clasificación y estadístico Kappa.

El modelo se entrena con el siguiente comando en la consola de MOA.

```
EvaluateModel -m (LearnModel -l trees.HoeffdingTree -s (generators.WaveformGenerator -i 1) \
-m 1000000) -s (generators.WaveformGenerator -i 4) -i 1000000
```

Realizamos una población de tamaño 30 utilizando 30 semillas distintas para comprobar cómo se comporta este algoritmo en general. Almacenamos los datos de accuracy y Kappa para las 30 ejecuciones en un dataframe.

```{r}
accuracy = array(dim = 30)
kappa = array(dim = 30)
for (i in 1:30) {
  archivo =
    paste(c(paste(c("./Datos/Ejercicio1.1/hoeffdingEstacionario",i),
                  collapse = ""),".csv"),collapse="")
  con = file(archivo,open="r")
  datos = readLines(con)
  accuracyFinal =
    as.double(gsub(",", ".", gsub(".* = ", "", datos[2])))
  accuracy[i] = accuracyFinal
  kappaFinal =
    as.double(gsub(",", ".", gsub(".* = ", "", datos[3])))
  kappa[i] = kappaFinal
  close(con)
}

hoeffdingEst = as.data.frame(cbind(accuracy, kappa))
hoeffdingEst
```

Ahí se pueden ver los valores que ha obtenido para accuracy y Kappa el modelo estacionario.

### Repetir el paso anterior, sustituyendo el clasificador por HoeffdingTree adaptativo.

Para ello utilizamos el mismo comando anterior pero sustituyendo `trees.HoeffdingTree` por `trees.HoeffdingAdaptiveTree`.
De nuevo generamos una población de tamaño 30 mediante un script.

```{r}
accuracy = array(dim = 30)
kappa = array(dim = 30)
for (i in 1:30) {
  archivo =
    paste(c(paste(c("./Datos/Ejercicio1.2/hoeffdingAdaptativo",i),
                  collapse = ""),".csv"),collapse="")
  con = file(archivo,open="r")
  datos = readLines(con)
  accuracyFinal =
    as.double(gsub(",", ".", gsub(".* = ", "", datos[2])))
  accuracy[i] = accuracyFinal
  kappaFinal =
    as.double(gsub(",", ".", gsub(".* = ", "", datos[3])))
  kappa[i] = kappaFinal
  close(con)
}

hoeffdingAd = as.data.frame(cbind(accuracy, kappa))
hoeffdingAd
```

### Responda a la pregunta: ¿Cree que algún clasificador es significativamente mejor que el otro en este tipo de problemas? Razone su respuesta.

Para responder a esta pregunta de forma adecuada deberíamos evaluar la similitud de los resultados de ambos algoritmos en base a tests estadísticos. Para saber si utilizar tests paramétricos o no paramétricos comprobamos con el test de Shapiro-Wilk si los valores siguen una distribución normal.

```{r}
shapiro.test(hoeffdingEst$accuracy)
shapiro.test(hoeffdingAd$accuracy)
```

Como el accuracy del modelo estacionario no sigue una distribución normal según el test, para comparar esta variable tendré que usar un test no paramétrico como Wilcoxon.

```{r}
wilcox.test(hoeffdingEst$accuracy, hoeffdingAd$accuracy, exact = FALSE, alternative = )
```

El test dice que hay diferencias significativas entre ambas poblaciones. Observemos los histogramas de los valores para entender qué está ocurriendo.

```{r}
hist(hoeffdingEst$accuracy, col="blue", prob=TRUE)
lines(density(hoeffdingEst$accuracy))

hist(hoeffdingAd$accuracy, col="red", prob=TRUE)
lines(density(hoeffdingAd$accuracy))
```

Como se puede observar, el Hoeffding adaptativo (en color rojo) sigue una distribución más normal que el estacionario (en color azul). El estacionario no ha sido clasificado como distribución normal debido a la oblicuidad hacia la derecha que sufre. Además, comprobamos que la gran mayoría de los resultados que obtiene el estacionario están a la derecha de 84.4, por lo que se entiende que salga elegido por Wilcoxon como el mejor algoritmo.

En un flujo que no tiene cambios de concepto es asumible pensar que el algoritmo estacionario se mantenga estable y funcione mejor de forma general a lo largo del tiempo que un modelo adaptativo que puede estar aprendiendo cosas erróneas con los distintos momentos del flujo.

## Ejercicio 2: Entrenamiento online.

### Entrenar un clasificador HoeffdingTree online, mediante el método Interleaved Test-Then-Train, sobre un total de 1.000.000 de instancias procedentes de un flujo obtenido por el generador WaveFormGenerator con semilla aleatoria igual a 2, con una frecuencia de muestreo igual a 10.000. Pruebe con otras semillas aleatorias para crear una población de resultados. Anotar los valores de porcentajes de aciertos en la clasificación y estadístico Kappa.

El comando para ejecutar uno de los métodos que piden en el enunciado es el siguiente.

```
EvaluateInterleavedTestThenTrain -l trees.HoeffdingAdaptiveTree -s \
(generators.WaveformGenerator -i 2) -i 1000000 -f 10000
```

Construimos igual que en el caso anterior una población de tamaño 30 utilizando un script, y añadimos los datos a una variable dataframe.

```{r}
accuracy = array(dim = 30)
kappa = array(dim = 30)
for (i in 1:30) {
  archivo =
    paste(c(paste(c("./Datos/Ejercicio2.1/hoeffdingEstacionario",i),collapse = ""),".csv"),collapse="")
  datos = read.csv(archivo)
  accuracyFinal =
    datos$classifications.correct..percent.[length(datos$classifications.correct..percent.)]
  accuracy[i] = accuracyFinal
  kappaFinal =
    datos$Kappa.Statistic..percent.[length(datos$Kappa.Statistic..percent.)]
  kappa[i] = kappaFinal
}

hoeffdingEst2 = as.data.frame(cbind(accuracy, kappa))
hoeffdingEst2
```

### Repetir el paso anterior, sustituyendo el clasificador por HoeffdingTree adaptativo.

El comando para conseguir uno de los métodos que pide el enunciado es el que se muestra a continuación.

```
EvaluateInterleavedTestThenTrain -l trees.HoeffdingAdaptiveTree -s \
(generators.WaveformGenerator -i 2) -i 1000000 -f 10000
```

Construimos la población con el script y obtenemos los datos de accuracy y Kappa.

```{r}
accuracy = array(dim = 30)
kappa = array(dim = 30)
for (i in 1:30) {
  archivo =
    paste(c(paste(c("./Datos/Ejercicio2.2/hoeffdingAdaptativo",i),collapse = ""),".csv"),collapse="")
  datos = read.csv(archivo)
  accuracyFinal =
    datos$classifications.correct..percent.[length(datos$classifications.correct..percent.)]
  accuracy[i] = accuracyFinal
  kappaFinal =
    datos$Kappa.Statistic..percent.[length(datos$Kappa.Statistic..percent.)]
  kappa[i] = kappaFinal
}

hoeffdingAd2 = as.data.frame(cbind(accuracy, kappa))
hoeffdingAd2
```

### Responda a la pregunta: ¿Cree que algún clasificador es mejor que el otro en este tipo de problemas? Razone su respuesta.

Vamos de nuevo a ejecutar el test de Shapiro-Wilk para ver qué test utilizar para comparar los resultados.

```{r}
shapiro.test(hoeffdingEst2$accuracy)
shapiro.test(hoeffdingAd2$accuracy)
```

Como las dos distribuciones parecen normales según el test de Shapiro-Wilk podemos probar a utilizar el test T de Student para ver si hay diferencias significativas entre ambos clasificadores.

```{r}
t.test(hoeffdingEst2$accuracy, hoeffdingAd2$accuracy)
```

Los dos clasificadores parecen comportarse igual según el test T de Student. Esto quiere decir que la diferencia entre sus medias no es suficientemente significativa. Tiene sentido dado que cuando es un aprendizaje online los datos que le van llegando al clasificador adaptativo ahora sí facilitan su aprendizaje y puede decidir mejor qué partes de su modelo son mejores. El modelo estacionario se mantiene en los mismos baremos que obtenía en el ejercicio anterior, igualando sus resultados con el modelo adaptativo, cuando antes era el que mejor clasificaba.

## Ejercicio 3: Entrenamiento online en datos con concept drift.

### Entrenar un clasificador HoeffdingTree online, mediante el método Interleaved Test-Then-Train, sobre un total de 2.000.000 de instancias muestreadas con una frecuencia de 100.000, sobre datos procedentes de un generador de flujos RandomRBFGeneratorDrift, con semilla aleatorio igual a 1 para generación de modelos y de instancias, generando 2 clases, 7 atributos, 3 centroides en el modelo, drift en todos los centroides y velocidad de cambio igual a 0.001. Pruebe con otras semillas aleatorias. Anotar los valores de porcentajes de aciertos en la clasificación y estadístico Kappa. Compruebe la evolución de la curva de aciertos en la GUI de MOA.

Así se genera el ejemplo que pide el enunciado.

```
EvaluateInterleavedTestThenTrain -l trees.HoeffdingTree -s \
(generators.RandomRBFGeneratorDrift -r 1 -i 1 -c 2 -a 7 -n 3 -s 0.001 -k 3) -i 1000000 -f 100000
```

Se genera una población con 30 ejecuciones con distintas semillas. Voy a mostrar solo una gráfica representativa de cómo se comporta este algoritmo para no llenar el PDF de gráficas similares.

```{r}
accuracy = array(dim = 30)
kappa = array(dim = 30)
for (i in 1:30) {
  archivo =
    paste(c(paste(c("./Datos/Ejercicio3.1/hoeffdingEstacionario",i),collapse = ""),".csv"),collapse="")
  datos = read.csv(archivo)
  accuracyFinal =
    datos$classifications.correct..percent.[length(datos$classifications.correct..percent.)]
  accuracy[i] = accuracyFinal
  kappaFinal =
    datos$Kappa.Statistic..percent.[length(datos$Kappa.Statistic..percent.)]
  kappa[i] = kappaFinal
  
  if (i == 1) {
    plot(datos$learning.evaluation.instances,
     datos$classifications.correct..percent.,
     "l", ylim = c(0,100), col = "blue")
  }
}

hoeffdingEst3 = as.data.frame(cbind(accuracy, kappa))
hoeffdingEst3
```

### Repetir el paso anterior, sustituyendo el clasificador por HoeffdingTree adaptativo.

Una ejecución del algoritmo se lanzaría con el siguiente comando.

```
EvaluateInterleavedTestThenTrain -l trees.HoeffdingAdaptiveTree -s \
(generators.RandomRBFGeneratorDrift -r 1 -i 1 -c 2 -a 7 -n 3 -s 0.001 -k 3) -i 1000000 -f 100000
```

De nuevo generamos otra población con 30 de estas ejecuciones.

```{r}
accuracy = array(dim = 30)
kappa = array(dim = 30)
for (i in 1:30) {
  archivo =
    paste(c(paste(c("./Datos/Ejercicio3.2/hoeffdingAdaptativo",i),collapse = ""),".csv"),collapse="")
  datos = read.csv(archivo)
  accuracyFinal =
    datos$classifications.correct..percent.[length(datos$classifications.correct..percent.)]
  accuracy[i] = accuracyFinal
  kappaFinal =
    datos$Kappa.Statistic..percent.[length(datos$Kappa.Statistic..percent.)]
  kappa[i] = kappaFinal
  
  if (i == 1) {
    plot(datos$learning.evaluation.instances,
     datos$classifications.correct..percent.,
     "l", ylim = c(0,100), col = "red")
  }
}

hoeffdingAd3 = as.data.frame(cbind(accuracy, kappa))
hoeffdingAd3
```

### Responda a la pregunta: ¿Cree que algún clasificador es mejor que el otro en este tipo de problemas? Razone su respuesta.

Vamos a probar con el test de Shapiro-Wilk si las distribuciones de los valores de accuracy son normales.

```{r}
shapiro.test(hoeffdingEst3$accuracy)
shapiro.test(hoeffdingAd3$accuracy)
```

Ambas siguen una distribución normal en base al test de Shapiro-Wilk, por lo que podemos ejecutar el test T de Student para ver si la diferencia entre sus medias es significativa. En base a lo observado en las gráficas parece obvio que sí, pero lo hacemos por asegurarnos.

```{r}
t.test(hoeffdingEst3$accuracy, hoeffdingAd3$accuracy)
```

El p-value es muy pequeño dejando claro que existen diferencias significativas, como habíamos visto antes claramente a favor del algoritmo adaptativo. Al ocurrir cambios de concepto en el flujo de datos, el algoritmo adaptativo es capaz de mejorar su modelo desechando aquellas partes que no clasifiquen bien. El estacionario por su parte no aprende tan rápido y por tanto va decayendo su acierto a medida que se suceden los cambios de concepto.